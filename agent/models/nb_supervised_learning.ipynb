{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2UmqMhHG3ad"
      },
      "source": [
        "# Apprendimento Supervisionato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sommario \n",
        "\n",
        "La rappresentazione tramite modello NDOM discussa nella sezione precedente ci ha permesso, di fatto, di ingegnerizzare e aggiungere al DS iniziale 8 nuove feature, `task1`, `task2`, ..., `task8`.\n",
        "In questa sezione costruiamo e valutiamo dei modelli di apprendimento supervisionato (SL) che eseguono un task di regressione, cioè predizione del valore della feature target `metric` avente dominio continuo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strumenti utilizzati\n",
        "\n",
        "Da una prima osservazione del numero di elementi del DS, possiamo concludere che non sarebbe conveniente implementare un modello complesso come un'ANN. I modelli costruiti in seguito sono modelli classici implementati tramite libreria [scikit-learn](https://scikit-learn.org/stable/modules/classes.html). Le operazioni più elementari su Dataset, matrici e array vengono fatte tramite [pandas](https://pandas.pydata.org/) e [numpy](https://numpy.org/).\n",
        "\n",
        "Prima però, bisogna effettuare una prima fase di Preprocessing e osservazione del DS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKrhNglYedjm"
      },
      "source": [
        "## Preprocessing del DS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eYqqbIsefaB"
      },
      "source": [
        "### Caricamento del DS e Feature Selection\n",
        "\n",
        "Innanzitutto, una prima osservazione da fare è che il DS che utilizzeremo per l'addestramento dei modelli non comprende la feature `page_ungrouped_multim` e `page_menu_or`. Ricordiamo che queste due feature sono dei fattori di decisione che l'utente considera osservando direttamente la pagina e che si ritengono non osservabili a partire dal solo codice sorgente. Discorso diverso vale per la feature `page_template` per la quale in questo progetto si assume che possa essere comunque estratta automaticamente a partire dal codice sorgente della pagina. Nella sezione del NDOM, per semplicità, l'utente lo inseriva manualmente piuttosto che ricavarla automaticamente. In futuro, questa operazione può essere automatizzata analizzando le risorse esterne (fogli di stile, codice JS, ...) che la pagina scarica dal server web.\n",
        "\n",
        "Inoltre, per questa sezione le feature `ds3_features_pk` vengono ignorate perchè stringhe di individuazione univoca della pagina.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "PH6mS-80ekg4",
        "outputId": "551404ff-f678-49c9-af9e-1fa62d5a5c70"
      },
      "outputs": [],
      "source": [
        "import agent.definitions as defs\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(defs.ds3_gt_final_path)\n",
        "\n",
        "ds3_features_pk = [\"school_id\", \"page_url\"]\n",
        "ds3_features_part1 = [\"page_menu_or\", \"page_ungrouped_multim\"] # osservate manualmente\n",
        "ds3_features_part2 = [ # osservate automaticamente\n",
        "    \"page_template\",\n",
        "    \"page_load_time_ms\",\n",
        "    \"page_width\",\n",
        "    \"page_height\",\n",
        "    \"NDOM_nodes\",\n",
        "    \"NDOM_height\",\n",
        "]\n",
        "ds3_features_part3 = [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\", \"task6\", \"task7\", \"task8\"]\n",
        "ds3_target = \"metric\"\n",
        "\n",
        "# features\n",
        "ds3_features = (\n",
        "    ds3_features_pk + ds3_features_part1 + ds3_features_part2 + ds3_features_part3\n",
        ")\n",
        "ds3_features.append(ds3_target)\n",
        "\n",
        "# >>>\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CIO1hmsofrV"
      },
      "source": [
        "### Rilevazione rumore nel DS\n",
        "\n",
        "In questa sezione andiamo a rilevare eventuali valori del DS che non rientrano nel dominio della feature associata. Conoscendo il dominio teorico di ciascuna feature, li rappresentiamo tutti in forma interpretabile del linguaggio Python, mediante un dizionario: i domini discreti sono il tipo `str` o una lista; i domini continui sono delle funzioni lambda.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS3v0g4lok8a",
        "outputId": "8f1e8f4e-5a87-4fae-b8c6-ecf52ca929be"
      },
      "outputs": [],
      "source": [
        "# estremi dei domini di alcune feature\n",
        "PAGE_TEMPLATE_MIN_VAL = 1\n",
        "PAGE_TEMPLATE_MAX_VAL = 9\n",
        "\n",
        "PAGE_MENU_OR_MIN_VAL = 0\n",
        "PAGE_MENU_OR_MAX_VAL = 3\n",
        "\n",
        "METRIC_MIN_VAL = 1\n",
        "METRIC_MAX_VAL = 5\n",
        "\n",
        "# domini feature. un dominio può essere un tipo, una lista\n",
        "# o una funzione lambda (per domini infiniti, cioè per features continue)\n",
        "ds3_gt_feature_domains = {\n",
        "    \"school_id\": str,\n",
        "    \"page_url\": str,\n",
        "    \"page_template\": [x for x in range(PAGE_TEMPLATE_MIN_VAL, PAGE_TEMPLATE_MAX_VAL + 1)],\n",
        "    \"page_menu_or\": [x for x in range(PAGE_MENU_OR_MIN_VAL, PAGE_MENU_OR_MAX_VAL + 1)],\n",
        "    \"page_ungrouped_multim\": lambda v: v >= 0 and v % 1 == 0, # numero naturale\n",
        "    \"metric\": lambda v: v >= METRIC_MIN_VAL and v <= METRIC_MAX_VAL,\n",
        "    \"page_load_time_ms\": lambda v: v >= 0,\n",
        "    \"page_width\": lambda v: v >= 0,\n",
        "    \"page_height\": lambda v: v >= 0,\n",
        "    \"NDOM_nodes\": lambda v: v >= 0 and v % 1 == 0,\n",
        "    \"NDOM_height\": lambda v: v >= 0 and v % 1 == 0,\n",
        "    \"task1\": lambda v: v >= 0,\n",
        "    \"task2\": lambda v: v >= 0,\n",
        "    \"task3\": lambda v: v >= 0,\n",
        "    \"task4\": lambda v: v >= 0,\n",
        "    \"task5\": lambda v: v >= 0,\n",
        "    \"task6\": lambda v: v >= 0,\n",
        "    \"task7\": lambda v: v >= 0,\n",
        "    \"task8\": lambda v: v >= 0,\n",
        "}\n",
        "# altra rappresentazione possibile del dominio di metric\n",
        "#\"metric\": [\n",
        "#    x / 10\n",
        "#    for x in range((1 * 10), (5 * 10 + int(0.1 * 10)))\n",
        "#],\n",
        "\n",
        "\n",
        "def get_features_types(feature_domains: dict):\n",
        "    \"\"\"Restituisce le features discrete e continue.\n",
        "\n",
        "    Args:\n",
        "        - features_domains: Dizionario feature:dominio che rispetta la sintassi espressa sopra.\n",
        "\n",
        "    Returns:\n",
        "        - features_d: Lista di features discrete.\n",
        "        - features_c: Lista di features continue.\n",
        "    \"\"\"\n",
        "\n",
        "    features_d = []\n",
        "    features_c = []\n",
        "\n",
        "    for feature, domain in feature_domains.items():\n",
        "        if (isinstance(domain, list)): # or (domain is str)\n",
        "            features_d.append(feature)\n",
        "        elif callable(domain) and isinstance(domain, type(lambda x: x)):\n",
        "            features_c.append(feature)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return features_d, features_c\n",
        "\n",
        "# >>>\n",
        "features_discrete, features_continuous = get_features_types(ds3_gt_feature_domains)\n",
        "print(f\"Discrete: {features_discrete}\")\n",
        "print(f\"Continuous: {features_continuous}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C1ki0a2nevL"
      },
      "source": [
        "Controlliamo il modo in cui le feature sono rappresentate all'interno DS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_lUwJg-o7Ei",
        "outputId": "ea472b99-634a-45ed-9b94-96482d462f90"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHvWP6lio-wY"
      },
      "source": [
        "Come possiamo vedere, tutte le feature  discrete (`page_template`, `page_menu_or`) sono già rappresentate in forma numerica, per cui non c'è bisogno di usare nessuno degli [Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) previsti dalla libreria scikit-learn. Piuttosto, facciamo in modo che le feature discrete vengano rappresentate  da numeri `int64` e non da `float64`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75rK3V5zwjjG",
        "outputId": "78787a86-e09a-4480-e3e7-d23c1ca3eed2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "float64 = np.dtype('float64')\n",
        "\n",
        "for feature_d in features_discrete:\n",
        "    if df[feature_d].dtype is float64:\n",
        "        df[feature_d] = df[feature_d].astype(np.int64)\n",
        "\n",
        "# >>>\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH636c4XbAzC"
      },
      "source": [
        "Controlliamo se esistono valori del DS che non rietrano nei rispettivi domini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vW4-g3lbrv5",
        "outputId": "2eb8a0de-77d3-4836-c9b8-60b9d701a12b"
      },
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "def is_in_feature_domain(domain, value) -> bool:\n",
        "    \"\"\"Dato il dominio di una feature, restituisce True se value compare nel dominio,\n",
        "    False altrimenti.\n",
        "\n",
        "    Args:\n",
        "        - domain: Dominio di una feature. Può essere un tipo (es. str), una lista o una funzione lambda.\n",
        "        - value: Valore da controllare.\n",
        "    \"\"\"\n",
        "\n",
        "    if domain is str:\n",
        "        return isinstance(value, str)\n",
        "\n",
        "    elif isinstance(domain, list):\n",
        "        return value in domain\n",
        "\n",
        "    elif callable(domain) and isinstance(domain, type(lambda x: x)):\n",
        "        return domain(value)\n",
        "\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def detect_noisy_rows_values(df: DataFrame, domains: dict):\n",
        "    \"\"\"Rileva quali sono le righe del DS df in cui almeno una feature non è corretta,\n",
        "    cioè non rientra nel suo dominio.\n",
        "\n",
        "    Args:\n",
        "        - df: Istanza Dataframe.\n",
        "        - ds_feature_domains: Dizionario feature:funzione di validazione.\n",
        "\n",
        "    Returns:\n",
        "        - noisy_rows: Righe in cui esiste almeno una colonna con valori errati.\n",
        "        - noisy_cols: Colonne i cui valori in corrispondenza sono errati.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Detecting noisy rows...\")\n",
        "    noisy_rows = set()\n",
        "    noisy_cols = set()\n",
        "\n",
        "    for column in list(domains.keys()):\n",
        "        serie = df[column]\n",
        "\n",
        "        for i, el in serie.items():\n",
        "            if not is_in_feature_domain(domains[column], el):\n",
        "                noisy_rows.add(i)\n",
        "                noisy_cols.add(df.columns.get_loc(column))\n",
        "\n",
        "    if noisy_rows:\n",
        "        print(f\"{len(noisy_rows)} noisy row(s) exist! Please check them.\")\n",
        "    else:\n",
        "        print(\"No noisy rows exist.\")\n",
        "\n",
        "    return list(noisy_rows), list(noisy_cols)\n",
        "\n",
        "\n",
        "# >>>\n",
        "noisy_rows, noisy_cols = detect_noisy_rows_values(df, ds3_gt_feature_domains)\n",
        "\n",
        "if noisy_rows:\n",
        "  print(df.iloc[noisy_rows, noisy_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUnPYfMD5u2A"
      },
      "source": [
        "Ri-effetuiamo la valutazione per i siti che compaiono in questa lista e inseriamole in un nuovo DS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTGRpXdA6OYG",
        "outputId": "730ad14c-48d9-4505-d78e-1d90338f2595"
      },
      "outputs": [],
      "source": [
        "ds = pd.read_csv(defs.ds3_gt_no_noise_path)\n",
        "\n",
        "# >>>\n",
        "noisy_rows, noisy_cols = detect_noisy_rows_values(ds, ds3_gt_feature_domains)\n",
        "\n",
        "if noisy_rows:\n",
        "  print(ds.iloc[noisy_rows, noisy_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb0iGqw1Ak-5"
      },
      "source": [
        "### Panoramica distribuzione valori e Feature Correlation\n",
        "\n",
        "Fino ad ora siamo giunti alla creazione del DS finale da usare per i modelli, ma non abbiamo ancora dato uno sguardo alla popolarità dei valori dei domini delle variabili. Per cui generiamo gli istogrammi indicanti la distribuzione dei dati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "w-VTqE1MB6D8",
        "outputId": "985506b5-0198-4ab5-ebca-3244b8f1972c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "hist_columns = ds3_features_part1 + ds3_features_part2 + ds3_features_part3\n",
        "hist_columns.append(ds3_target)\n",
        "\n",
        "# >>>\n",
        "ds.hist(column=hist_columns, figsize=(14,12), bins=25)\n",
        "plt.suptitle(\"Distribution for each feature domain value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmkGQR10CAT8"
      },
      "source": [
        "Facciamo alcune osservazioni:\n",
        "- I template più popolari sono senza dubbio il #5 e #8, anche se c'è una buona quantità di siti che non seguono un modello vero e proprio (#9).\n",
        "- Riguardo all'orientamento dei menu, ~94% di siti presentano un menu orizzontale. ~20% delle pagine con un menu orizzontale ne presentano anche un altro verticale.\n",
        "- Riguardo il numero di elementi multimediali non raggruppati, le pagine confermano il trend (se vogliamo negativo) di banner e/o video sparsi senza criterio sulla pagina: solo il ~19% ne presenta 0, tutti i restanti ne hanno almeno uno.\n",
        "- Per l'istogramma relativo alla metrica notiamo che la scala verticale si ferma a poco meno di 200, per cui non c'è un valore del dominio di `metric` che \"monopolizza\" il DS.\n",
        "- In generale, tutte le features continue mostrate nel grafico non seguono una distribuzione normale. \n",
        "\n",
        "Di seguito è anche possibile visualizzare la correlazione che c'è tra ciascuna feature, e più in particolare, è di nostro interesse la misura con cui ciascuna input feature incide sulla feature target `metric`. Ne traiamo le seguenti osservazioni:\n",
        "- Nel quadrante in basso a destra si nota una correlazione diretta (positiva) tra le feature `taskx`. Il motivo potrebbe essere che, poichè i task dipendono tutti dalla struttura della pagina e dalla struttura dei menu, se l'utente fatica a trovare un certo task (ad es. il Regolamento di Istituto, che è il `task2`), faticherà anche a trovare i task simili (l'organigramma scolastico, che è il `task5` ed è un task più o meno inerente al Regolamento.)\n",
        "- Il quadrato blu indica una correlazione alta (ma comunque < -1) e inversa tra `metric` e `page_ungrouped_multim`: aumentano gli elementi multimediali confusionari, diminuisce la valutazione.\n",
        "\n",
        "Ovviamente questa Feature Heatmap non può generalizzare troppo, è da ritenersi come una semplice rappresentazione grafica del GT. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "Cl3UpXmwB053",
        "outputId": "ae6b622e-c660-4b06-83fe-9912da491286"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "ds_correlation = ds.drop(ds3_features_pk+features_discrete, axis=1).corr(method=\"pearson\")\n",
        "sns.heatmap(ds_correlation, linewidths=0.5, linecolor='darkgray', cmap=\"coolwarm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFNLdl1Am_q-"
      },
      "source": [
        "## Modelli di regressione e decisioni di progetto\n",
        "\n",
        "In questa sezione cerchiamo il/i modello/i che si avvicina di più al Ground Truth, mettendoli tutti su una stessa scala di giudizio, ovvero le metriche di misurazione degli errori.\n",
        "\n",
        "A causa numero piuttosto limitati di esempi del DS, assumiamo che le metriche di un qualsiasi modello devono essere calcolate facendo in modo che il modello possa sfruttare i dati dell'intero DS. Per questo motivo, possiamo dire che la tecnica di [k-fold Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html) verrà impiegata in due casistiche:\n",
        "- vogliamo ottenere delle metriche di errore affidabili per un determinato modello, magari quando sappiamo a priori una certa configurazione di iperparametri. Solamente in questo caso la CV genera k Split, cioè k modalità di utilizzo **di tutto il DS**.\n",
        "- vogliamo trovare una configurazione ottimale di iperparametri per un determinato modello. In questo caso, dobbiamo prima nascondere il TE dai modelli e in seguito applicare la CV usando i dati del TS.\n",
        "\n",
        "Di seguito andiamo a creare `X` (DS ridotto alle sole feature di input) e `y` (DS ridotto alla feature target `metric`). Successivamente, dividiamo il DS in TS e TE secondo il rapporto 7.5:2.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# dataset-------\n",
        "ds3_features_excluded = ds3_features_pk + ds3_features_part1\n",
        "ds3_features_excluded.append(ds3_target)\n",
        "\n",
        "# X (tabella con colonne input feature) e y (tabella target)\n",
        "X_DS = ds.drop(ds3_features_excluded, axis=1)\n",
        "y_DS = ds[ds3_target]\n",
        "\n",
        "# anche in forma di ndarray per numpy\n",
        "X_DS_ = X_DS.to_numpy()\n",
        "y_DS_ = y_DS.to_numpy()\n",
        "\n",
        "# TS e TE-------\n",
        "X_TS, X_TE, gt_y_TS, gt_y_TE = train_test_split(X_DS, y_DS, test_size=0.25, random_state=42)\n",
        "\n",
        "# anche in forma di ndarray per numpy\n",
        "X_TS_ = X_TS.to_numpy()\n",
        "gt_y_TS_ = gt_y_TS.to_numpy()\n",
        "X_TE_ = X_TE.to_numpy()\n",
        "gt_y_TE_ = gt_y_TE.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxnlPBJb8JzO"
      },
      "source": [
        "### Regressore Lineare\n",
        "\n",
        "Il regressore lineare utiizza il metodo dei minimi quadrati per calcolare i coefficienti di una retta di regressione. Non ci sono iperparametri da ottimizzare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSL346o4mOOg"
      },
      "source": [
        "#### 1^ Costruzione (senza k-fold CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS9IvXWMBVAn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# modello\n",
        "regLin = LinearRegression()\n",
        "regLin.fit(X_TS, gt_y_TS)\n",
        "\n",
        "# predizione\n",
        "regLin_y_TS = regLin.predict(X_TS)\n",
        "regLin_y_TE = regLin.predict(X_TE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19JIzEOEOlXV"
      },
      "source": [
        "##### OSSERVAZIONE: Cambio categoria e penalità applicata all'errore\n",
        "\n",
        "Dopo aver costruito il modello, diamo un'occhiata ai valori effettivi della feature target (nel TS) e le relative previsioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEN8xxQepooE",
        "outputId": "82f1db18-2350-41d3-f01d-82d7a57d6d54"
      },
      "outputs": [],
      "source": [
        "from pandas import Series\n",
        "# https://stackoverflow.com/a/42476224\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# >>>\n",
        "gt_y_TE # fisso\n",
        "Series(regLin_y_TE) # fisso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iYjaKHUPXKj"
      },
      "source": [
        "Calcoliamo manualmente l'errore che otteniamo. Questa operazione sarà poi automatizzata, ma per il momento lo facciamo per avere una panoramica sulle percentuali di errore fatte dal modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAfwa2-3pzN0",
        "outputId": "7547023f-656d-428f-ace6-4912172d09a0"
      },
      "outputs": [],
      "source": [
        "regLin_err = np.subtract(regLin_y_TE, gt_y_TE) # fisso\n",
        "\n",
        "# >>>\n",
        "regLin_err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8LptErU8fHD"
      },
      "source": [
        "Il calcolo \"manuale\" dell'errore che il modello fa sul target **di questo specifico TE** è stato fatto per poter vedere quante volte il modello fa una previsione che si discosta dal valore attuale di una certa percentuale. L'istogramma generato di seguito ne è una rappresentazione grafica e solo in questa evenienza si è calcolato l'errore con segno. In seguito, quando si andrà a calcolare le metriche dei modelli, si useranno le metriche convenzionali di misurazione dell'errore.\n",
        "\n",
        "Sull'asse X dell'istogramma ci sono le possibili percentuali di errore (da -100% a 100%) ad indicare il fatto che questo modello può fare una previsione con un errore percentuale negativo (il modello predice una valutazione minore della valutazione reale), uguale a 0, o positivo.\n",
        "Ad es. un errore -100% si verifica quando il valore attuale di `metric` è 5 e il modello predice 1. In corrispondenza di una percentuale, sull'asse Y il grafico dice per quanti esempi del TS il modello fa una predizione con questo errore percentuale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "eXdqLGMc39Ro",
        "outputId": "27cd93e8-fdeb-4b68-b0a3-718a0b404bbe"
      },
      "outputs": [],
      "source": [
        "# conosciamo il valore di un ipotetico errore massimo\n",
        "max_error = METRIC_MAX_VAL - METRIC_MIN_VAL\n",
        "\n",
        "def calc_err_percentage(x):\n",
        "    perc = float((x*100)/max_error)\n",
        "    return int(perc)\n",
        "\n",
        "def plot_err_perc(model_err:Series):\n",
        "    # creo una nuova serie che associa ad ogni elemento la sua percentuale di errore\n",
        "    model_err_perc = model_err.apply(calc_err_percentage)\n",
        "    model_err_perc = model_err_perc.rename(\"Error percentage between predicted value and actual value\")\n",
        "\n",
        "    model_err_perc_count = model_err_perc.value_counts()\n",
        "    model_err_perc_count = model_err_perc_count.reindex(range(-100, 101), fill_value=0)\n",
        "    model_err_perc_count = model_err_perc_count.sort_index()\n",
        "\n",
        "    model_err_perc_count.plot(kind='bar', figsize=(15,5))\n",
        "\n",
        "plot_err_perc(regLin_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "848LfpiIY8R2"
      },
      "source": [
        "Il modello (sugli esempi di questo specifico TE) non fa errori molto gravi (vale a dire tanti errori minori del -50% o maggiori del 50%) ma possiamo fare una osservazione.\n",
        "\n",
        "Consideriamo una pagina web per il quale la valutazione è 3.2. Se il modello fa un errore (anche piccolo) di -0.4 punti, si verifica un vero e proprio cambio categoria: il sito teoricamente è *Accettabile*, ma il modello lo classifica come *Confuso* (3.2-0.4=2.8). Situazione diversa si ha se il modello fa un errore (ancora piccolo) di 0.4 punti, e quindi il modello predice il valore 3.6, senza predire un cambio categoria.\n",
        "\n",
        "**Sarebbe corretto in questa casistica parlare di errori equivalenti?**\n",
        "- Se il nostro task di interesse fosse stato di classificazione, avremmo ipotizzato di no.\n",
        "- Nel nostro caso, ipotizziamo che tali errori siano equivalenti, a fronte del fatto che, dopo varie esecuzioni, le metriche di performance dei modelli che ricalcolano le predizioni (cioè applicando le penalità) non si discostano dai valori di quelli che non lo fanno. I modelli che applicano la penalità, in altre parole, sono \"forzati\" a compiere un errore quanto più basso possibile soprattutto per le pagine la cui valutazione è a un'estremità (inferiore o superiore) della categoria corrente.\n",
        "\n",
        "\n",
        "In ogni caso, la penalità che calcoliamo viene definita con la funzione `calc_err_penalty` che si comporta nel seguente modo:\n",
        "- se non c'è un cambio categoria, l'errore del modello non subisce una penalità.\n",
        "- se c'è un cambio categoria allora viene applicata la penalità, che dipende dal numero di categorie tra quella attuale e quella prevista. Eventualmente, possiamo anche prevedere delle penalità più severe se il modello predice una categoria peggiore rispetto a quella attuale (`page_category_shift` < 0).\n",
        "Il comportamento di questa funzione è visibile da questo [grafico](https://www.desmos.com/calculator/5y734tuqft). Avremmo potuto implementare questa funzione con un semplice if-else, però il grafico (poichè non è simmetrico all'asse Y) evidenzia il fatto delle penalità più severe quando `page_category_shift` < 0. Infine, dobbiamo precisare che le penalità relative a quando `page_category_shift` < 0 devono avere segno negativo, altrimenti andrebbero contro il nostro intento. Per comodità, nel grafico, tutte le penalità hanno segno positivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyLSsTjzp1Ff"
      },
      "outputs": [],
      "source": [
        "def calc_err_penalty(y_gt, y_pred):\n",
        "    \"\"\" Calcola la penalità da sommare all'errore qualora c'è un cambio categoria.\n",
        "\n",
        "    Args:\n",
        "        - y_gt: Target attuale.\n",
        "        - y_pred: Target previsto dal modello (include un errore).\n",
        "    \"\"\"\n",
        "\n",
        "    pred_category = int(y_pred) # positivo\n",
        "    gt_category = int(y_gt) # positivo\n",
        "\n",
        "    page_category_shift = pred_category - gt_category\n",
        "    #page_category_shift può essere < 0 (modello predice categoria più bassa)\n",
        "    # = 0 (stessa categoria)\n",
        "    # > 0 (modello predice categoria più alta)\n",
        "\n",
        "    if page_category_shift == 0:\n",
        "        return y_pred\n",
        "\n",
        "    elif (page_category_shift < 0 and gt_category <= METRIC_MIN_VAL) or \\\n",
        "        (page_category_shift > 0 and gt_category >= METRIC_MAX_VAL - 1):\n",
        "        # c'è un cambio categoria ma non lo consideriamo tale\n",
        "        return y_pred\n",
        "\n",
        "    else:\n",
        "        # calcolo penalty\n",
        "        a = 0.006 #0.009\n",
        "        b = -0.0008 #-0.0008\n",
        "        c = 0.108 #0.009\n",
        "        penalty = (((a)*(page_category_shift**2))+\n",
        "                ((b)*page_category_shift)+\n",
        "                (c)\n",
        "        )\n",
        "        if page_category_shift < 0:\n",
        "            penalty = penalty*(-1)\n",
        "        # ---\n",
        "\n",
        "        err_category = int(y_pred + penalty) # positivo\n",
        "\n",
        "        if pred_category == err_category:\n",
        "            return y_pred + penalty\n",
        "\n",
        "        # evito che la penalità sia eccessiva\n",
        "        elif page_category_shift < 0:\n",
        "            return y_pred + (pred_category - y_pred) #y_pred + (<0)\n",
        "        else:\n",
        "            #return y_pred + (penalty - (y_pred + penalty - err_category + 0.1))\n",
        "            return y_pred + (err_category - y_pred - 0.1)\n",
        "\n",
        "# vettorizza funzione\n",
        "vcalc_err_penalty = np.vectorize(calc_err_penalty, otypes=[float])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2^ Costruzione (con k-fold CV)\n",
        "\n",
        "Di seguito implementiamo manualmente una procedura di k-fold CV che fa uso di uno scaler. Essa fa comunque un test sistematico degli iperparametri, come avviene nel [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Inoltre nella CV usiamo un numero di fold `k = 5`, che equivale a un rapporto TS:VS = 8:2. Con la CV possiamo ricavare delle metriche di performance che dipendono da **tutto il DS** e non da una singola parte.\n",
        "\n",
        "I Regressori Lineari, poichè calcolano coefficienti di apprendimento mediante discesa di gradiente, sono sensibili al feature scaling. Con il feature scaling, infatti, l'algoritmo di discesa del gradiente converge più velocemente al minimo. In questo progetto usiamo un [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr-0KMVKqvyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "from sklearn.base import RegressorMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "def custom_kf_cv(\n",
        "                X, y,\n",
        "                m:RegressorMixin, m_name,\n",
        "                param_grid:ParameterGrid,\n",
        "                k,\n",
        "                scaler:MinMaxScaler,\n",
        "                apply_penalty=False,\n",
        "                plot_err=False):\n",
        "    \"\"\"Costruisce il modello m per il quale esistono iperparametri inseriti in param_grid.\n",
        "    Per ciascuna configurazione di iperparametri, applica la k-fold CV usando i dati di X e y.\n",
        "    Restituisce una lista di Dataframe, una per ogni configurazione di iperparametri.\n",
        "\n",
        "    Args:\n",
        "        - X: dati delle input feature.\n",
        "        - y: dati della target feature.\n",
        "        - m: modello di regressione.\n",
        "        - m_name: Nome del modello.\n",
        "        - param_grid (ParameterGrid). Oggetto contenente i domini degli iperparametri.\n",
        "        - k: numero di folds.\n",
        "        - scaler: oggetto MinMaxScaler.\n",
        "        - apply_penalty. Default: false\n",
        "        - plot_err: True se si vuole mostrare l'istogramma degli errori percentuali. Default: false.\n",
        "    \n",
        "    Returns:\n",
        "        - model_perf: Un array di DataFrame (un DataFrame per ogni possibile combinazione di iperparametri)\n",
        "    \"\"\"\n",
        "\n",
        "    # lista di possibili combinazioni di iperparametri\n",
        "    param_combos = [' ']\n",
        "    if param_grid is None or len(param_grid) == 0:\n",
        "        param_exist = False\n",
        "    else:\n",
        "        param_combos = list(param_grid)\n",
        "        param_exist = True\n",
        "\n",
        "    # i dati vengono prima mescolati in modo casuale prima di essere suddivisi in test/training.\n",
        "    kf_logic = KFold(n_splits=k, shuffle=True, random_state=77)\n",
        "\n",
        "    # restituisco una lista di dataframe, uno per ogni combinazione di iperparametri\n",
        "    model_perf = [DataFrame() for param_combo_id in param_combos]\n",
        "\n",
        "    # itera sulle possibili configurazioni di iperparametri\n",
        "    param_combo_id = 0\n",
        "    for param_combo in param_combos:\n",
        "\n",
        "        # Creo k split a partire da X e y.\n",
        "        # X e y possono rappresentare l'intero DS, oppure il TS.\n",
        "        # https://stats.stackexchange.com/questions/339736/perform-cross-validation-on-train-set-or-entire-data-set\n",
        "        kf_splits = kf_logic.split(X=X, y=y)\n",
        "\n",
        "        # itera sugli split\n",
        "        split_no = 1\n",
        "        for TS_idx, TE_idx in kf_splits:\n",
        "            # considero l'i-esimo split (su 10).\n",
        "            # questo split si compone da 9 folds per il TS (che in totale formano X_TS_fold e gt_y_TS_fold)\n",
        "            # e 1 fold per il TE (anche chiamato Validation) (formata da X_TE_fold e gt_y_TE_fold).\n",
        "            # man mano che si cicla su questo for, gli elementi del TS e TE cambiano\n",
        "\n",
        "            X_TS_fold,    X_TE_fold    = X[TS_idx], X[TE_idx]\n",
        "            gt_y_TS_fold, gt_y_TE_fold = y[TS_idx], y[TE_idx]\n",
        "\n",
        "            # scaling (va fatto sempre dopo lo split)\n",
        "            if scaler is not None:\n",
        "                scaler.fit(X_TS_fold)\n",
        "                X_TS_fold = scaler.transform(X_TS_fold)\n",
        "                # https://stats.stackexchange.com/q/319514\n",
        "                X_TE_fold = scaler.transform(X_TE_fold)\n",
        "            \n",
        "            # modello\n",
        "            if param_exist:\n",
        "                model = m.set_params(**param_combo)\n",
        "            else:\n",
        "                model = m\n",
        "            model.fit(X_TS_fold, gt_y_TS_fold)\n",
        "\n",
        "            # predizione\n",
        "            model_y_TS_fold = model.predict(X_TS_fold)\n",
        "            if apply_penalty:\n",
        "                model_y_TS_fold = vcalc_err_penalty(gt_y_TS_fold, model_y_TS_fold)\n",
        "            model_y_TS_fold = np.clip(model_y_TS_fold, METRIC_MIN_VAL, METRIC_MAX_VAL)\n",
        "            \n",
        "            model_y_TE_fold = model.predict(X_TE_fold)\n",
        "            if apply_penalty:\n",
        "                model_y_TE_fold = vcalc_err_penalty(gt_y_TE_fold, model_y_TE_fold)\n",
        "            model_y_TE_fold = np.clip(model_y_TE_fold, METRIC_MIN_VAL, METRIC_MAX_VAL)\n",
        "\n",
        "            # valutazione\n",
        "            fold_index = f\"{m_name} (Split {split_no})\"\n",
        "\n",
        "            model_perf[param_combo_id] = pd.concat([\n",
        "                    model_perf[param_combo_id],\n",
        "                    pd.DataFrame([{\n",
        "                            \"MAE (TS)\": mean_absolute_error(gt_y_TS_fold, model_y_TS_fold),\n",
        "                            \"MSE (TS)\": mean_squared_error(gt_y_TS_fold, model_y_TS_fold),\n",
        "                            \"RMSE (TS)\": mean_squared_error(gt_y_TS_fold, model_y_TS_fold, squared=False),\n",
        "                            \"R^2 (TS)\": r2_score(gt_y_TS_fold, model_y_TS_fold),\n",
        "\n",
        "                            \"MAE (TE)\": mean_absolute_error(gt_y_TE_fold, model_y_TE_fold),\n",
        "                            \"MSE (TE)\": mean_squared_error(gt_y_TE_fold, model_y_TE_fold),\n",
        "                            \"RMSE (TE)\": mean_squared_error(gt_y_TE_fold, model_y_TE_fold, squared=False),\n",
        "                            \"R^2 (TE)\": r2_score(gt_y_TE_fold, model_y_TE_fold)\n",
        "                        }], index=[fold_index]\n",
        "                    )\n",
        "                ],\n",
        "                axis = 0\n",
        "            )\n",
        "\n",
        "            if plot_err and split_no == 2:\n",
        "                plot_err_perc(model_err=Series(np.subtract(model_y_TE_fold, gt_y_TE_fold)))\n",
        "\n",
        "            # vai al prossimo split\n",
        "            split_no = split_no + 1\n",
        "\n",
        "        # Aggiungi una nuova riga al fondo del DataFrame con le medie\n",
        "        avg_index = f\"Average ({str(param_combo)})\" if param_exist else \"Average\"\n",
        "        means = model_perf[param_combo_id].mean()\n",
        "\n",
        "        model_perf[param_combo_id] = pd.concat(\n",
        "            [\n",
        "                model_perf[param_combo_id],\n",
        "                pd.DataFrame(\n",
        "                    [means], index=[avg_index], columns=means.index\n",
        "                )\n",
        "            ],\n",
        "            axis = 0\n",
        "        )\n",
        "\n",
        "        param_combo_id = param_combo_id + 1\n",
        "\n",
        "    return model_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Costruiamo il modello con la funzione appena scritta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ARLFxnbKhPm9",
        "outputId": "103a7b94-a338-442b-9e7e-cad039053517"
      },
      "outputs": [],
      "source": [
        "regLin_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                            m=LinearRegression(),\n",
        "                            m_name=\"Linear Regressor\",\n",
        "                            param_grid=None,\n",
        "                            k=5,\n",
        "                            scaler=MinMaxScaler())\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regLin_perf)} model performance table(s) available.\")\n",
        "regLin_perf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regressore KNN\n",
        "\n",
        "Un Regressore KNN è inerente all'approccio Case-Based dell'Apprendimento Supervisionato. Il modello non calcola dei coefficienti numerici come nel Regressore Lineare, ma predice il target dell'istanza online guardando gli esempi più simili ad essa. Questi ultimi NON vengono individuati con un semplice scanning completo del TS (sarebbe dispendioso), ma mediante costruzione di una struttura dati Kd-Tree. Le prestazioni di questi tipi di metodi dipendono in modo cruciale dal Feature Scaling.\n",
        "\n",
        "Il nostro iperparametro di interesse è n_neighbors. In generale, i domini degli iperparametri considerati sono:\n",
        "- `n_neighbors` può andare da 1 a 20.\n",
        "- `weights` può essere `distance`, in cui gli esempi più vicini hanno peso che dipende da quanto sono simili all'istanza online; `uniform` quando hanno peso uguale. \n",
        "- `algorithm = kd_tree`.\n",
        "\n",
        "Gli iperparametri ottimali sono mostrati nella tabella delle performance mostrata di seguito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# iperparametri\n",
        "regKNN_params = {\n",
        "    'n_neighbors': range(1, 21),\n",
        "    'weights': ['distance', 'uniform'],\n",
        "    'algorithm': ['kd_tree']\n",
        "}\n",
        "\n",
        "# ricerca migliore configurazione di iperparametri\n",
        "regKNN_grid = GridSearchCV(\n",
        "    estimator=KNeighborsRegressor(),\n",
        "    param_grid=regKNN_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    refit=False, # lo faccio manualmente dopo\n",
        "    return_train_score=True\n",
        ")\n",
        "regKNN_grid.fit(X=X_TS, y=gt_y_TS)\n",
        "regKNN_params_best = regKNN_grid.best_params_\n",
        "\n",
        "# calcolo metriche\n",
        "# lista adatta al ParameterGrid\n",
        "regKNN_params_best = {k: [v] if not isinstance(v, list) else v for k, v in regKNN_params_best.items()}\n",
        "regKNN_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                                    m=KNeighborsRegressor(),\n",
        "                                    m_name=\"KNN\",\n",
        "                                    param_grid=ParameterGrid(regKNN_params_best),\n",
        "                                    k=5,\n",
        "                                    scaler=MinMaxScaler(),\n",
        "                                    plot_err=True)\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regKNN_perf)} model performance table available.\")\n",
        "regKNN_perf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'istogramma qui sopra presentato fa vedere come, se prendiamo in considerazione la migliore configurazione di iperparametri, nel momento in cui andiamo ad addestrare questo modello sui dati del TS e lo valutiamo sui dati del VS, il numero di esempi con errore percentuale 0% è di gran lunga maggiore rispetto a prima. Questo modello, inoltre, non fa errori gravi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_cv_results(model_grid, model_name):\n",
        "    cv_results_table = pd.DataFrame(model_grid.cv_results_)\n",
        "    cv_results_table.to_excel(f\"./cv_results/{model_name}.xlsx\", sheet_name=model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regressore con Alberi di Decisione\n",
        "\n",
        "I Regressori (e Classificatori) basati su Alberi di Decisione non necessitano di Feature Scaling perchè fanno scelte di partizionamento del DS basate su una soglia del dominio di una feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# iperparametri\n",
        "regDet_params = {\n",
        "    'criterion': ['friedman_mse', 'squared_error', 'poisson'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 5, 10, 15, 45, 90],\n",
        "    'min_samples_leaf': [1, 5, 20, 50, 90],\n",
        "    'min_samples_split': [2, 5, 10, 40, 60, 100, 150],\n",
        "    'random_state': [1]\n",
        "}\n",
        "\n",
        "# ricerca migliore configurazione di iperparametri\n",
        "regDet_grid = GridSearchCV(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    param_grid=regDet_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    refit=False\n",
        ")\n",
        "regDet_grid.fit(X=X_TS, y=gt_y_TS)\n",
        "regDet_params_best = regDet_grid.best_params_\n",
        "save_cv_results(regDet_grid, \"regDet\")\n",
        "\n",
        "# calcolo metriche\n",
        "# lista adatta al ParameterGrid\n",
        "regDet_params_best = {k: [v] if not isinstance(v, list) else v for k, v in regDet_params_best.items()}\n",
        "regDet_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                                    m=DecisionTreeRegressor(random_state=1),\n",
        "                                    m_name=\"Decision Tree\",\n",
        "                                    param_grid=ParameterGrid(regDet_params_best),\n",
        "                                    k=5,\n",
        "                                    scaler=None)\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regDet_perf)} model performance table available.\")\n",
        "regDet_perf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regressore SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# iperparametri\n",
        "regSVR_params = {\n",
        "    'kernel': ['rbf'],\n",
        "    'C': [0.1, 1, 10, 15, 20, 100],\n",
        "    'epsilon': [0.1, 0.2, 0.5, 1, 2],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "\n",
        "# ricerca migliore configurazione di iperparametri\n",
        "regSVR_grid = GridSearchCV(\n",
        "    estimator=SVR(),\n",
        "    param_grid=regSVR_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    refit=False,\n",
        ")\n",
        "regSVR_grid.fit(X=X_TS, y=gt_y_TS)\n",
        "regSVR_params_best = regSVR_grid.best_params_\n",
        "save_cv_results(regSVR_grid, \"regSVR\")\n",
        "\n",
        "# calcolo metriche\n",
        "# lista adatta al ParameterGrid\n",
        "regSVR_params_best = {k: [v] if not isinstance(v, list) else v for k, v in regSVR_params_best.items()}\n",
        "regSVR_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                                    m=SVR(),\n",
        "                                    m_name=\"SVR\",\n",
        "                                    param_grid=ParameterGrid(regSVR_params_best),\n",
        "                                    k=5,\n",
        "                                    scaler=MinMaxScaler())\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regSVR_perf)} model performance table available.\")\n",
        "regSVR_perf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regressore Random Forest\n",
        "\n",
        "Il regressore Random Forest rientra tra le tecniche Ensemble di SL. A partire da un TS, addestra più alberi di regressione, tenendo conto che ciascun albero può basarsi su una partizione del TS originale diversa da quella di un altro albero. Una volta che tutti gli alberi hanno predetto un valore, la tecnica Random Forest restituisce un valore ottenuto dalla combinazione dei precedenti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# iperparametri\n",
        "regRaF_params = {\n",
        "    'criterion': ['friedman_mse', 'squared_error'],\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 15, 22],\n",
        "    'min_samples_leaf': [1, 5, 20],\n",
        "    'min_samples_split': [2, 50, 120],\n",
        "    'random_state': [66],\n",
        "    'bootstrap': [True]\n",
        "}\n",
        "\n",
        "# ricerca migliore configurazione di iperparametri\n",
        "regRaF_grid = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(),\n",
        "    param_grid=regRaF_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    refit=False,\n",
        ")\n",
        "regRaF_grid.fit(X=X_TS, y=gt_y_TS)\n",
        "regRaF_params_best = regRaF_grid.best_params_\n",
        "save_cv_results(regRaF_grid, \"regRaF\")\n",
        "\n",
        "# calcolo metriche\n",
        "# lista adatta al ParameterGrid\n",
        "regRaF_params_best = {k: [v] if not isinstance(v, list) else v for k, v in regRaF_params_best.items()}\n",
        "regRaF_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                                    m=RandomForestRegressor(random_state=66),\n",
        "                                    m_name=\"Random Forest\",\n",
        "                                    param_grid=ParameterGrid(regRaF_params_best),\n",
        "                                    k=5,\n",
        "                                    scaler=None)\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regRaF_perf)} model performance table available.\")\n",
        "regRaF_perf[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regressore Gradient Boosting\n",
        "\n",
        "Il regressore Gradient Boosting rientra anch'esso tra le tecniche Ensemble di SL, ma, a differenza del Random Forest, usa un approccio di boosting, cioè crea un nuovo albero di decisione sulla base degli esiti ottenuti dell'albero precedente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "regGrB_params = {\n",
        "    'criterion': ['friedman_mse'],\n",
        "    'n_estimators': [50, 100],\n",
        "    'learning_rate': [0.05, 0.1, 0.5],\n",
        "    'max_depth': [10, 22],\n",
        "    'min_samples_leaf': [1, 5, 20],\n",
        "    'min_samples_split': [2, 50, 120],\n",
        "    'random_state': [66]\n",
        "}\n",
        "\n",
        "# ricerca migliore configurazione di iperparametri\n",
        "regGrB_grid = GridSearchCV(\n",
        "    estimator=GradientBoostingRegressor(),\n",
        "    param_grid=regGrB_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    refit=False,\n",
        ")\n",
        "regGrB_grid.fit(X=X_TS, y=gt_y_TS)\n",
        "regGrB_params_best = regGrB_grid.best_params_\n",
        "save_cv_results(regGrB_grid, \"regGrB\")\n",
        "\n",
        "# calcolo metriche\n",
        "# lista adatta al ParameterGrid\n",
        "regGrB_params_best = {k: [v] if not isinstance(v, list) else v for k, v in regGrB_params_best.items()}\n",
        "regGrB_perf = custom_kf_cv(X=X_DS_, y=y_DS_,\n",
        "                                    m=GradientBoostingRegressor(random_state=66),\n",
        "                                    m_name=\"Random Forest\",\n",
        "                                    param_grid=ParameterGrid(regGrB_params_best),\n",
        "                                    k=5,\n",
        "                                    scaler=None)\n",
        "\n",
        "# >>>\n",
        "print(f\"{len(regGrB_perf)} model performance table available.\")\n",
        "regGrB_perf[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "6126b564a5d1e2c6e99ae68d8ec250149d00b6eefd8728f1ca2a8862c1e8aa2a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
